{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb86d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommaso\\AppData\\Local\\Temp\\ipykernel_3364\\4026529702.py:77: UserWarning: Pandas requires version '1.4.3' or newer of 'xlsxwriter' (version '1.3.7' currently installed).\n",
      "  with pd.ExcelWriter(excel_file_path) as writer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file with separate sheets saved to C:\\Users\\Tommaso\\Documents\\GitHub\\Data-Collection\\pareto_frontier_example\\merged_output_new_v1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define methods to obtain the final database\n",
    "def merge_csv_files(source_dir, destination_dir):\n",
    "    # Create a dictionary to store dataframes for each folder\n",
    "    dfs = {}\n",
    "\n",
    "    # Create a dictionary to store NPC and Emissions from pareto_point.csv\n",
    "    pareto_data = {}\n",
    "\n",
    "    # Iterate over files in the source directory\n",
    "    for root, _, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is a CSV and not one of the excluded files\n",
    "            if file.endswith('.csv') and file not in ['unmet_demand.csv', 'unmet_demand_annual.csv', 'pareto_point.csv']:\n",
    "\n",
    "                folder_name = os.path.basename(root)\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Read the CSV into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Add columns for the folder name (Scenario) and file name\n",
    "                df['Scenario'] = folder_name\n",
    "                original_file_name = os.path.splitext(file)[0]\n",
    "                df['OriginalFileName'] = original_file_name\n",
    "\n",
    "                # Store the DataFrame in the dictionary\n",
    "                dfs.setdefault(folder_name, []).append(df)\n",
    "\n",
    "            # Check for pareto_point.csv and extract NPC and Emissions\n",
    "            if file == 'pareto_point.csv':\n",
    "                folder_name = os.path.basename(root)\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read pareto_point.csv\n",
    "                pareto_df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Extract NPC and Emissions values (assuming they're in row 1, col 2 for NPC and col 3 for emissions)\n",
    "                npc_value = pareto_df.iloc[0, 1]  # NPC is in row 1, col 2 (0-based index)\n",
    "                emissions_value = pareto_df.iloc[0, 2]  # Emissions is in row 1, col 3 (0-based index)\n",
    "                \n",
    "                # Store the values in the pareto_data dictionary for each scenario\n",
    "                pareto_data[folder_name] = {\n",
    "                    'Scenario': folder_name,\n",
    "                    'NPC': npc_value,\n",
    "                    'Emissions': emissions_value\n",
    "                }\n",
    "\n",
    "    # Merge dataframes for each folder\n",
    "    merged_dfs = {}\n",
    "    for folder_name, dfs_list in dfs.items():\n",
    "        merged_dfs[folder_name] = pd.concat(dfs_list, ignore_index=True)\n",
    "\n",
    "    # Identify available scenarios (folders)\n",
    "    available_scenarios = [str(i) for i in range(1, 11) if str(i) in merged_dfs]\n",
    "\n",
    "    # Concatenate dataframes for available scenarios into a single dataframe\n",
    "    if available_scenarios:\n",
    "        merged_df = pd.concat([merged_dfs[scenario] for scenario in available_scenarios], ignore_index=True)\n",
    "\n",
    "        # Drop the 'Unnamed: 0' (i.e. the first column of each .csv file), 'Emission' (i.e. column specifying the kind of emission), and 'Region' columns if they exist\n",
    "        merged_df.drop(columns=[col for col in ['Unnamed: 0', \n",
    "                                                'Emission' \n",
    "                                                ] if col in merged_df], inplace=True)\n",
    "\n",
    "        # Copy 'Datetime' values to 'Year' where 'Year' is empty\n",
    "        if 'Year' in merged_df and 'Datetime' in merged_df:\n",
    "            merged_df['Year'].fillna(merged_df['Datetime'], inplace=True)\n",
    "            merged_df.drop(columns=['Datetime'], inplace=True)\n",
    "\n",
    "        # Remove columns with all NaN/empty values in the merged DataFrame\n",
    "        merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "        # Write the merged dataframe to an Excel file with a separate sheet for each 'OriginalFileName'\n",
    "        excel_file_path = os.path.join(destination_dir, 'merged_db.xlsx')\n",
    "        with pd.ExcelWriter(excel_file_path) as writer:\n",
    "            # Create a separate sheet for each unique value in the 'OriginalFileName' column\n",
    "            for original_file_name, group_df in merged_df.groupby('OriginalFileName'):\n",
    "                # Remove 'OriginalFileName' column\n",
    "                group_df = group_df.drop(columns=['OriginalFileName'])\n",
    "                # Remove columns with all NaN/empty values before writing\n",
    "                group_df.dropna(axis=1, how='all', inplace=True)\n",
    "                group_df.to_excel(writer, index=False, sheet_name=original_file_name[:31])  # Limit sheet name length to 31 characters\n",
    "\n",
    "            # Add a new sheet for NPC and Emissions data (pareto_point)\n",
    "            if pareto_data:\n",
    "                pareto_df = pd.DataFrame(pareto_data.values())  # Convert pareto_data dict to DataFrame\n",
    "                # Remove columns with all NaN/empty values before writing\n",
    "                pareto_df.dropna(axis=1, how='all', inplace=True)\n",
    "                pareto_df.to_excel(writer, index=False, sheet_name='pareto_point')  # Write the pareto_data to the pareto_point sheet\n",
    "\n",
    "        print(f\"Merged file with separate sheets saved to {excel_file_path}\")\n",
    "    else:\n",
    "        print(\"No valid scenarios found. No file created.\")\n",
    "\n",
    "# Apply the method above:\n",
    "source_directory = r'C:\\Users\\Tommaso\\Documents\\GitHub\\Data-Collection\\pareto_frontier_example'\n",
    "destination_directory = r'C:\\Users\\Tommaso\\Documents\\GitHub\\Data-Collection\\pareto_frontier_example'\n",
    "\n",
    "merge_csv_files(source_directory, destination_directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a5945-fb8b-45de-a967-f22695a9ce86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764d5f8-efed-4ae3-be0e-7b7a29088a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypatia_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
